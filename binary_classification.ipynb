{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Text Classification\n",
    "\n",
    "### Source\n",
    "Algorithm was copy & pasted from this [Medium article](https://bmanikan.medium.com/text-classification-a-parameter-free-method-with-compressors-b96cd151adbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "\n",
    "test_set = test[['OriginalTweet','Sentiment']]\n",
    "training_set = train[['OriginalTweet','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [(row['OriginalTweet'],row['Sentiment']) for idx, row in test_set.iterrows()]\n",
    "training_set = [(row['OriginalTweet'],row['Sentiment']) for idx, row in training_set.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'negative&&positive&&TRENDING: New Yorkers encounter empty supermarket shelves (pictured, Wegmans in Brooklyn), sold-out online grocers (FoodKick, MaxDelivery) as #coronavirus-fearing shoppers stock up https://t.co/Gr76pcrLWh https://t.co/ivMKMsqdT1''\n",
      "====================================================================================================\n",
      "'positive&&positive&&When I couldn't find hand sanitizer at Fred Meyer, I turned to #Amazon. But $114.97 for a 2 pack of Purell??!!Check out how  #coronavirus concerns are driving up prices. https://t.co/ygbipBflMY''\n",
      "====================================================================================================\n",
      "'negative&&positive&&#Panic buying hits #NewYork City as anxious shoppers stock up on food&amp;medical supplies after #healthcare worker in her 30s becomes #BigApple 1st confirmed #coronavirus patient OR a #Bloomberg staged event?\n",
      "\n",
      "https://t.co/IASiReGPC4\n",
      "\n",
      "#QAnon #QAnon2018 #QAnon2020 \n",
      "#Election2020 #CDC https://t.co/29isZOewxu''\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Copy paste from: https://bmanikan.medium.com/text-classification-a-parameter-free-method-with-compressors-b96cd151adbb\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "# Define the function to calculate NCD\n",
    "def calculate_ncd(x1, x2):\n",
    "    Cx1 = len(gzip.compress(x1.encode()))\n",
    "    Cx2 = len(gzip.compress(x2.encode()))\n",
    "    x1x2 = \" \".join([x1, x2])\n",
    "    Cx1x2 = len(gzip.compress(x1x2.encode()))\n",
    "    ncd = (Cx1x2 - min(Cx1, Cx2)) / max(Cx1, Cx2)\n",
    "    return ncd\n",
    "\n",
    "# Define the function for k-NN classification\n",
    "def knn_classify(test_instance, training_set, k):\n",
    "    distance_from_test_instance = []\n",
    "    for (x2, _) in training_set:\n",
    "        ncd = calculate_ncd(test_instance, x2)\n",
    "        distance_from_test_instance.append(ncd)\n",
    "    sorted_idx = np.argsort(np.array(distance_from_test_instance))\n",
    "    top_k_class = [training_set[i][1] for i in sorted_idx[:k]]\n",
    "    predict_class = max(set(top_k_class), key=top_k_class.count)\n",
    "    return predict_class\n",
    "\n",
    "# # Example texts\n",
    "# test_set = [\n",
    "#     (\"soccer is wonderful game\", _),\n",
    "#     (\"I love pizza man\", _)\n",
    "# ]\n",
    "\n",
    "# training_set = [\n",
    "#     (\"I love pizza\", \"Class A\"),\n",
    "#     (\"Ice cream is delicious\", \"Class A\"),\n",
    "#     (\"Basketball requires good coordination\", \"Class B\"),\n",
    "#     (\"Soccer is a wonderful game\", \"Class B\"),\n",
    "#     (\"Tennis need efforts\", \"Class B\")\n",
    "# ]\n",
    "\n",
    "k = 5  # Number of neighbors to consider\n",
    "\n",
    "# Apply the k-NN classification to the test set\n",
    "for (test_instance, _) in test_set[:3]:\n",
    "    predicted_class = knn_classify(test_instance, training_set, k)\n",
    "    print(f\"'{_}&&{predicted_class}&&{test_instance}''\\n{'='*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the same thing but with sklearn. Hopefully it's faster/more accurate?\n",
    "# Use GridsearchCV https://towardsdatascience.com/cross-validation-and-grid-search-efa64b127c1b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
